{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e6e4ed",
   "metadata": {},
   "source": [
    "# UTS Klasifikasi LDA Naive Bayes & SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc26f5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (1.7.2)\n",
      "Requirement already satisfied: gensim in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (4.3.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (7.3.1)\n",
      "Requirement already satisfied: click in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn gensim nltk pandas numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6cb5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b471b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import gensim\n",
    "    from gensim import corpora, models\n",
    "    HAS_GENSIM = True\n",
    "except Exception:\n",
    "    HAS_GENSIM = False\n",
    "\n",
    "try:\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    sastrawi_stemmer = StemmerFactory().create_stemmer()\n",
    "    HAS_SASTRAWI = True\n",
    "except Exception:\n",
    "    HAS_SASTRAWI = False\n",
    "    sastrawi_stemmer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5480707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"Berita.csv\"  \n",
    "MERGE_TITLE = True\n",
    "NUM_TOPICS = 10           \n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "PERFORM_CV = False       \n",
    "CV_FOLDS = 5\n",
    "MIN_TOKEN_LEN = 3\n",
    "FILTER_DICT_MIN = 5      \n",
    "FILTER_DICT_MAX_PCT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9948604",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_stop = {\n",
    "\"yang\",\"dan\",\"di\",\"ke\",\"dari\",\"pada\",\"untuk\",\"dengan\",\"atau\",\"adalah\",\"ini\",\"itu\",\"sebagai\",\"oleh\",\"karena\",\"agar\",\n",
    "\"bisa\",\"juga\",\"sangat\",\"tidak\",\"dalam\",\"antara\",\"lebih\",\"jika\",\"tetapi\",\"namun\",\"per\",\"setiap\",\"hingga\",\"sehingga\",\n",
    "\"memiliki\",\"telah\",\"baru\",\"saja\",\"kami\",\"kita\",\"anda\",\"dia\",\"mereka\",\"seperti\",\"ada\",\"apa\",\"siapa\",\"dimana\",\"kapan\",\n",
    "\"bagaimana\",\"yaitu\",\"maupun\",\"lain\",\"lainnya\",\"oleh\",\"setelah\",\"sebelum\",\"sejak\",\"masih\",\"harus\"\n",
    "}\n",
    "eng_stop = {\"the\",\"and\",\"is\",\"in\",\"to\",\"of\",\"a\",\"for\",\"on\",\"that\",\"with\",\"as\",\"by\",\"an\",\"are\",\"was\",\"be\",\"from\"}\n",
    "STOPWORDS = set([w.lower() for w in ind_stop]) | eng_stop\n",
    "\n",
    "def preprocess_text(s, stem=HAS_SASTRAWI):\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'http\\S+|www\\.\\S+', ' ', s)\n",
    "    s = re.sub(r'\\S+@\\S+', ' ', s)\n",
    "    s = re.sub(r'[^a-z\\s]', ' ', s)\n",
    "    tokens = s.split()\n",
    "    tokens = [t for t in tokens if len(t) >= MIN_TOKEN_LEN and t not in STOPWORDS]\n",
    "    if stem and sastrawi_stemmer is not None:\n",
    "        try:\n",
    "            tokens = [sastrawi_stemmer.stem(t) for t in tokens]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8d6ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {CSV_PATH}\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "if MERGE_TITLE and \"judul\"  in df.columns and \"berita\" in df.columns:\n",
    "    df['text'] = df['judul'].fillna('') + \". \" + df['berita'].fillna('')\n",
    "elif \"berita\" in df.columns:\n",
    "    df['text'] = df['berita'].fillna('')\n",
    "else:\n",
    "    raise ValueError(\"Kolom 'berita' tidak ditemukan.\")\n",
    "\n",
    "if \"kategori\" not in df.columns:\n",
    "    raise ValueError(\"Kolom 'kategori' (label) tidak ditemukan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f4c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].astype(str).apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f5f4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_GENSIM:\n",
    "    tokenized = [t.split() for t in df['text_clean'].tolist()]\n",
    "    dictionary = corpora.Dictionary(tokenized)\n",
    "    dictionary.filter_extremes(no_below=FILTER_DICT_MIN, no_above=FILTER_DICT_MAX_PCT, keep_n=10000)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in tokenized]\n",
    "    lda = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=NUM_TOPICS, random_state=RANDOM_STATE, passes=10, alpha='auto', eta='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1e70714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:  indonesia, piala, timnas, main, aff, vietnam, dua, sama\n",
      "Topic 1:  persen, prabowo, menteri, perintah, program, tahun, makan, gizi\n",
      "Topic 2:  indonesia, latih, main, saya, timnas, kluivert, ahsan, tanding\n",
      "Topic 3:  red, sparks, megawati, menang, poin, liga, jalan, jakarta\n",
      "Topic 4:  pesawat, uang, persen, jabat, tahun, orang, air, lapor\n",
      "Topic 5:  israel, senjata, gaza, gencat, hamas, palestina, serang, sepakat\n",
      "Topic 6:  bakar, presiden, negara, yoon, trump, orang, perintah, los\n",
      "Topic 7:  laut, pagar, tangerang, menteri, kpk, nelayan, kkp, ikan\n",
      "Topic 8:  korban, banjir, orang, warga, polisi, kasus, duga, rumah\n",
      "Topic 9:  menit, gol, main, gawang, hasil, dua, babak, unggul\n"
     ]
    }
   ],
   "source": [
    "for tid in range(NUM_TOPICS):\n",
    "        print(f\"Topic {tid}: \", \", \".join([w for w,_ in lda.show_topic(tid, topn=8)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6794292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bentuk matriks X: (1500, 10)\n",
      "                                                text   Topic_0   Topic_1  \\\n",
      "0  Airlangga Harap Kenaikan UMP Tingkatkan Daya B...  0.000164  0.998526   \n",
      "1  PT SIER Beri Penghargaan untuk 50 Tenant Terba...  0.000168  0.896207   \n",
      "2  Prabowo Bakal Bentuk Kementerian Penerimaan Ne...  0.000195  0.934493   \n",
      "3  Sinergi Kemenag & BPJS Ketenagakerjaan Lindung...  0.000242  0.980760   \n",
      "4  Pemerintah Segera Bentuk Satgas PHK Usai Tetap...  0.000200  0.998198   \n",
      "5  AHY Buka-bukaan Nasib Kelanjutan Pembangunan I...  0.000189  0.998301   \n",
      "6  Badan Gizi Soal Biaya Makan Gratis Rp10 Ribu: ...  0.000217  0.998048   \n",
      "7  Zulhas Minta Tambahan Anggaran Rp510 M Demi Ca...  0.000184  0.998345   \n",
      "8  PLN Akan Uji Coba PLTS IKN 22 Desember. Uji co...  0.181992  0.815390   \n",
      "9  Profil Jhony Saputra, Anak Haji Isam yang Jadi...  0.000305  0.368914   \n",
      "\n",
      "    Topic_2   Topic_3   Topic_4   Topic_5   Topic_6   Topic_7   Topic_8  \\\n",
      "0  0.000170  0.000163  0.000156  0.000150  0.000189  0.000164  0.000166   \n",
      "1  0.000174  0.078739  0.023870  0.000154  0.000194  0.000168  0.000170   \n",
      "2  0.000203  0.000194  0.063939  0.000179  0.000225  0.000195  0.000197   \n",
      "3  0.000252  0.000241  0.000230  0.000223  0.017339  0.000242  0.000245   \n",
      "4  0.000208  0.000199  0.000190  0.000184  0.000231  0.000200  0.000203   \n",
      "5  0.000196  0.000188  0.000179  0.000173  0.000218  0.000189  0.000191   \n",
      "6  0.000226  0.000216  0.000206  0.000199  0.000250  0.000217  0.000220   \n",
      "7  0.000191  0.000183  0.000175  0.000169  0.000212  0.000184  0.000186   \n",
      "8  0.000340  0.000326  0.000311  0.000301  0.000378  0.000327  0.000331   \n",
      "9  0.000317  0.078139  0.550795  0.000280  0.000352  0.000305  0.000309   \n",
      "\n",
      "    Topic_9 kategori  \n",
      "0  0.000152  Ekonomi  \n",
      "1  0.000156  Ekonomi  \n",
      "2  0.000181  Ekonomi  \n",
      "3  0.000225  Ekonomi  \n",
      "4  0.000186  Ekonomi  \n",
      "5  0.000176  Ekonomi  \n",
      "6  0.000202  Ekonomi  \n",
      "7  0.000171  Ekonomi  \n",
      "8  0.000304  Ekonomi  \n",
      "9  0.000284  Ekonomi  \n"
     ]
    }
   ],
   "source": [
    "def doc2vec(bow):\n",
    "        vec = np.zeros(NUM_TOPICS)\n",
    "        for tid, prob in lda.get_document_topics(bow, minimum_probability=0.0):\n",
    "            vec[tid] = prob\n",
    "        return vec\n",
    "X = np.array([doc2vec(b) for b in corpus])\n",
    "y = df['kategori'].astype(str).values\n",
    "\n",
    "X = np.array([doc2vec(b) for b in corpus])\n",
    "y = df['kategori'].astype(str).values\n",
    "\n",
    "print(\"Bentuk matriks X:\", X.shape)\n",
    "\n",
    "topic_cols = [f\"Topic_{i}\" for i in range(NUM_TOPICS)]\n",
    "df_topics = pd.DataFrame(X, columns=topic_cols)\n",
    "df_topics['kategori'] = y\n",
    "\n",
    "df_show = pd.concat([df[['text']].reset_index(drop=True), df_topics], axis=1)\n",
    "\n",
    "print(df_show.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b71c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38988656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HASIL NAÏVE BAYES ===\n",
      "Akurasi: 0.8166666666666667\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ekonomi       0.73      0.91      0.81        75\n",
      "Internasional       0.88      0.79      0.83        75\n",
      "     Nasional       0.68      0.59      0.63        75\n",
      "     Olahraga       0.99      0.99      0.99        75\n",
      "\n",
      "     accuracy                           0.82       300\n",
      "    macro avg       0.82      0.82      0.81       300\n",
      " weighted avg       0.82      0.82      0.81       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "print(\"=== HASIL NAÏVE BAYES ===\")\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7558cfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HASIL SVM ===\n",
      "Akurasi: 0.84\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Ekonomi       0.73      0.91      0.81        75\n",
      "Internasional       0.95      0.81      0.88        75\n",
      "     Nasional       0.74      0.64      0.69        75\n",
      "     Olahraga       0.96      1.00      0.98        75\n",
      "\n",
      "     accuracy                           0.84       300\n",
      "    macro avg       0.85      0.84      0.84       300\n",
      " weighted avg       0.85      0.84      0.84       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "print(\"=== HASIL SVM ===\")\n",
    "print(\"Akurasi:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
