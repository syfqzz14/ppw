{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2adda714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting builtwith\n",
      "  Downloading builtwith-1.3.4.tar.gz (34 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\syafiq azizi\\appdata\\roaming\\python\\python312\\site-packages (from builtwith) (1.17.0)\n",
      "Building wheels for collected packages: builtwith\n",
      "  Building wheel for builtwith (setup.py): started\n",
      "  Building wheel for builtwith (setup.py): finished with status 'done'\n",
      "  Created wheel for builtwith: filename=builtwith-1.3.4-py3-none-any.whl size=36133 sha256=386f10871930d563f18f6f3a1ed4a009b0ea77254c925eebffbe5cb7beeadbf5\n",
      "  Stored in directory: c:\\users\\syafiq azizi\\appdata\\local\\pip\\cache\\wheels\\7f\\2d\\b2\\606e3df914d4aeeab99c4a4e3e9a61673d2293c2e346db00c8\n",
      "Successfully built builtwith\n",
      "Installing collected packages: builtwith\n",
      "Successfully installed builtwith-1.3.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'builtwith' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'builtwith'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install builtwith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60cd8485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'web-servers': ['Nginx'], 'javascript-frameworks': ['jQuery', 'jQuery UI']}\n"
     ]
    }
   ],
   "source": [
    "import builtwith\n",
    "\n",
    "# Analisis teknologi yang digunakan\n",
    "res = builtwith.parse('https://pta.trunojoyo.ac.id')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6767107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2: Daftar Karya Ilmiah\n",
      "URL: index.html | Teks: \n",
      "URL: # | Teks: 14677Journal\n",
      "URL: https://pta.trunojoyo.ac.id/ | Teks: Beranda\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/ | Teks: Pencarian\n",
      "URL: https://pta.trunojoyo.ac.id/c_template/ | Teks: Download\n",
      "URL: https://library.trunojoyo.ac.id/detil.php?id=23 | Teks: Petunjuk Upload\n",
      "URL: https://pta.trunojoyo.ac.id/c_contact/ | Teks: Kontak\n",
      "URL: # | Teks: STRATEGI PENGEMBANGAN MAKANAN DAN MINUMAN KHAS PULAU GILIGENTING GUNA MENDUKUNG PARIWISATA BERKELANJUTAN\n",
      "URL: https://pta.trunojoyo.ac.id/welcome/detail/170361100003 | Teks: Selengkapnya\n",
      "URL: # | Teks: PERUMUSAN SANKSI PIDANA BAGI MASYARAKAT SEKITAR HUTAN YANG MELAKUKAN PENCURIAN KAYU MILIK NEGARA DALAM UNDANG-UNDANG NOMOR 18 TAHUN 2013\n",
      "URL: https://pta.trunojoyo.ac.id/welcome/detail/170111100053 | Teks: Selengkapnya\n",
      "URL: # | Teks: Peran Teor Motivasi Herzberg Sebagai Mediator Self Efficacy, Lingkungan Kerja Dalam Meningkatkan Prestasi Kerja Pegawai ( Kantor Jasa Penilai Publik Guntur Eki Andri dan Rekan Kota Surabaya )\n",
      "URL: https://pta.trunojoyo.ac.id/welcome/detail/160211100116 | Teks: Selengkapnya\n",
      "URL: https://pta.trunojoyo.ac.id/welcome/index/2 | Teks: 2\n",
      "URL: https://pta.trunojoyo.ac.id/welcome/index/3 | Teks: 3\n",
      "URL: https://pta.trunojoyo.ac.id/welcome/index/2 | Teks: >\n",
      "URL: https://pta.trunojoyo.ac.id/welcome/index/4893 | Teks: Â»\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/1 | Teks: Hukum\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/1 | Teks: Ilmu Hukum\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/24 | Teks: Magister Ilmu Hukum\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/2 | Teks: Pertanian\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/2 | Teks: Teknologi Industri Pertanian\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/3 | Teks: Agribisnis\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/4 | Teks: Agroteknologi\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/5 | Teks: Ilmu Kelautan\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/35 | Teks: Manajemen Sumberdaya Perairan\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/37 | Teks: Magister Pengelolaan Sumber Daya Alam\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/3 | Teks: Ekonomi Dan Bisnis\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/6 | Teks: Ekonomi Pembangunan\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/7 | Teks: Manajemen\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/8 | Teks: Akuntansi\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/21 | Teks: D3 Akuntansi\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/22 | Teks: Magister Manajemen\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/25 | Teks: Magister Akuntansi\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/26 | Teks: D3 Enterpreneurship\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/36 | Teks: Magister Ilmu Ekonomi\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/41 | Teks: Doktor Ilmu Manajemen\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/4 | Teks: Teknik\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/9 | Teks: Teknik Industri\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/10 | Teks: Teknik Informatika\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/11 | Teks: Manajemen Informatika\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/19 | Teks: Teknik Multimedia Dan Jaringan\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/20 | Teks: Mekatronika\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/23 | Teks: Teknik Elektro\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/31 | Teks: Sistem Informasi\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/32 | Teks: Teknik Mesin\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/33 | Teks: Teknik Mekatronika\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/5 | Teks: Ilmu Sosial Dan Ilmu Budaya\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/12 | Teks: Sosiologi\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/13 | Teks: Ilmu Komunikasi\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/14 | Teks: Psikologi\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/15 | Teks: Sastra Inggris\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/6 | Teks: Keislaman\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/16 | Teks: Ekonomi Syariah\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/17 | Teks: Hukum Bisnis Syariah\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/7 | Teks: Ilmu Pendidikan\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/18 | Teks: Pgsd\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/27 | Teks: Pendidikan Bhs Dan Sastra Indonesia\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/28 | Teks: Pendidikan Informatika\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/29 | Teks: Pendidikan Ipa\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/30 | Teks: Pgpaud\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/38 | Teks: Pendidikan Profesi Guru\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/99 | Teks: Mbkm\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/99 | Teks: Mbkm\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/100 | Teks: Pascasarjana\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/39 | Teks: Magister Pendidikan Dasar\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byprod/40 | Teks: Doktor Pengelolaan Sumber Daya Alam\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/1 | Teks: Hukum\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/2 | Teks: Pertanian\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/3 | Teks: Ekonomi Dan Bisnis\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/4 | Teks: Teknik\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/5 | Teks: Ilmu Sosial Dan Ilmu Budaya\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/6 | Teks: Keislaman\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/7 | Teks: Ilmu Pendidikan\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/99 | Teks: Mbkm\n",
      "URL: https://pta.trunojoyo.ac.id/c_search/byfac/100 | Teks: Pascasarjana\n",
      "URL: http://trunojoyo.ac.id | Teks: www.trunojoyo.ac.id\n",
      "URL: http://e-journal.dikti.go.id | Teks: http://e-journal.dikti.go.id\n",
      "URL: # | Teks: \n",
      "URL: # | Teks: \n",
      "URL: # | Teks: \n",
      "URL: # | Teks: \n",
      "URL: # | Teks: \n",
      "URL: # | Teks: \n",
      "URL: # | Teks: \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def crawl_website(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Ambil semua judul h1, h2, h3\n",
    "        headings = soup.find_all(['h1', 'h2', 'h3'])\n",
    "        for heading in headings:\n",
    "            print(f\"{heading.name}: {heading.get_text()}\")\n",
    "\n",
    "        # Ambil semua link\n",
    "        links = soup.find_all('a', href=True)\n",
    "        for link in links:\n",
    "            print(f\"URL: {link['href']} | Teks: {link.get_text()}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Terjadi kesalahan saat mengakses {url}: {e}\")\n",
    "\n",
    "# Gunakan fungsi\n",
    "crawl_website(\"https://pta.trunojoyo.ac.id/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e60025e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================================================\n",
      "No.  | Prodi                | Penulis                   | Judul                                                        | Pembimbing I              | Pembimbing II            \n",
      "======================================================================================================================================================\n",
      "\n",
      "Scraping data for program: Ilmu Hukum\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1    | Ilmu Hukum           | Dyah Ayu Citra Seza       | Implementasi Fungsi Legislasi Dewan Perwakilan Rakyat Daerah | Yudi Widagdo Harimurti, S | Safi', SH., MH           \n",
      "2    | Ilmu Hukum           | Maulina Nurlaily          | Pertanggungjawaban Pidana Direksi BUMN (Persero)\n",
      "(Anotasi P | Tolib Effendi, SH., MH.   | Dr. Eni Suastuti, SH., Mh\n",
      "3    | Ilmu Hukum           | Moh. Samsul Hidayat       | Analisis Terhadap Kekosongan Hukum dalam Pengawasan Peredara | Tolib Effendi, SH., MH.   | Agus Ramdlany, SH., MH.  \n",
      "4    | Ilmu Hukum           | TOMMY ADITYA PARLINDUNGAN | PERLINDUNGAN HUKUM BAGI KONSUMEN ATAS PRODUK ELEKTRONIK YANG | DR. DJULAEKA, S.H., M.HUM | DR.USWATUN HASANAH, S.H.,\n",
      "5    | Ilmu Hukum           | RICA YENA IMADHORA        | TELAAH  KRITIS TENTANG ALASAN HUKUM YANG DIGUNAKAN OLEH  PAP | Dr. DENI SBY, S. H., M. S | SAIFUL ABDULLAH, S. H., M\n",
      "6    | Ilmu Hukum           | Andri Eka Sugiarto        | TELAAH KRITIS TENTANG\n",
      "PEMBERITAAN MEDIA MASSA TERHADAP PELA | Dr. Deni Setya Bagus Yuhe | Gatoet Poernomo,SH.M.Hum \n",
      "7    | Ilmu Hukum           | Agung Saiful Anam         | PELAKSANAAN PENDAFTARAN TANAH UNTUK PERTAMA KALI DI KANTOR P | Dr. Mufarrijul Ikhwan, SH | Mishbahul Munir, SH., M.H\n",
      "8    | Ilmu Hukum           | Adityo Nugroho            | TRANSAKSI JUAL BELI MELALUI INTERNET PERSPEKTIF SYARIAH\n",
      "( K | Dr. Murni, SH.,M.Hum      | Mishbahul Munir, SH., M.H\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 170\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# Run the full scraping process\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43mscrape_pta_limited\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36mscrape_pta_limited\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    121\u001b[39m jurnal_url = jurnal.select_one(\u001b[33m'\u001b[39m\u001b[33ma.gray.button\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mhref\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjurnal_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     response.raise_for_status()\n\u001b[32m    126\u001b[39m     soup1 = BeautifulSoup(response.content, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\http\\client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def get_text_or_na(soup, selectors):\n",
    "    \"\"\"Mencoba beberapa selektor untuk menemukan teks, mengembalikan 'N/A' jika tidak ditemukan.\"\"\"\n",
    "    for selector in selectors:\n",
    "        element = soup.select_one(selector)\n",
    "        if element:\n",
    "            text = element.get_text(strip=True)\n",
    "            if text and text.strip():\n",
    "                return text.strip()\n",
    "    return 'N/A'\n",
    "\n",
    "def get_data_from_span(soup, text_contains):\n",
    "    \"\"\"Mencari span yang berisi teks tertentu dan mengekstrak nama setelah titik dua.\"\"\"\n",
    "    span = soup.select_one(f'span:-soup-contains(\"{text_contains}\")')\n",
    "    if span:\n",
    "        text = span.get_text(strip=True)\n",
    "        if ':' in text:\n",
    "            return text.split(':', 1)[1].strip()\n",
    "    return 'N/A'\n",
    "\n",
    "def get_abstract_robust(soup, keywords):\n",
    "    \"\"\"\n",
    "    Mencari tag heading (b) yang teksnya mengandung salah satu dari kata kunci\n",
    "    dan mengekstrak paragraf berikutnya.\n",
    "    \"\"\"\n",
    "    for tag_b in soup.find_all('b'):\n",
    "        tag_text = tag_b.get_text(strip=True)\n",
    "        if any(keyword.lower() in tag_text.lower() for keyword in keywords):\n",
    "            parent_div = tag_b.find_parent('div')\n",
    "            if parent_div:\n",
    "                next_div_sibling = parent_div.find_next_sibling('div')\n",
    "                if next_div_sibling:\n",
    "                    p_tag = next_div_sibling.find('p', align=\"justify\")\n",
    "                    if p_tag:\n",
    "                        abstract_text = p_tag.get_text(strip=True)\n",
    "                        if abstract_text:\n",
    "                            return abstract_text\n",
    "    return 'N/A'\n",
    "\n",
    "def get_total_pages(soup):\n",
    "    \"\"\"\n",
    "    Mengekstrak total jumlah halaman dari navigasi paginasi.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pagination = soup.select_one('ol.pagination')\n",
    "        if pagination:\n",
    "            last_page_li = pagination.select('li')[-1]\n",
    "            last_page_link = last_page_li.select_one('a')\n",
    "            if last_page_link and 'href' in last_page_link.attrs:\n",
    "                url_path = last_page_link['href']\n",
    "                return int(url_path.split('/')[-1])\n",
    "    except (IndexError, ValueError, KeyError):\n",
    "        pass\n",
    "    return 1\n",
    "\n",
    "def scrape_pta_limited():\n",
    "    \"\"\"\n",
    "    Scrapes a limited number of titles and abstracts (max 100 per program)\n",
    "    from the Universitas Trunojoyo Madura's final project repository (PTA).\n",
    "    \"\"\"\n",
    "    base_url = \"https://pta.trunojoyo.ac.id/\"\n",
    "    MAX_RECORDS_PER_PRODI = 100\n",
    "\n",
    "    prodi_data = []\n",
    "    try:\n",
    "        r = requests.get(base_url)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        prodi_links = soup.find_all('a', href=lambda href: href and 'c_search/byprod/' in href)\n",
    "\n",
    "        for link in prodi_links:\n",
    "            prodi_name = link.get_text(strip=True)\n",
    "            prodi_url = link['href']\n",
    "            prodi_data.append({'name': prodi_name, 'url': prodi_url})\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the main page: {e}\", file=sys.stderr)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_scraped_data = {\n",
    "        \"penulis\": [], \"judul\": [], \"pembimbing_pertama\": [], \"pembimbing_kedua\": [],\n",
    "        \"abstrak_indonesia\": [], \"abstrak_inggris\": [], \"prodi\": []\n",
    "    }\n",
    "    \n",
    "    total_data_count = 0\n",
    "\n",
    "    # Print table header for live console output\n",
    "    print(\"=\" * 150)\n",
    "    print(f\"{'No.':<4} | {'Prodi':<20} | {'Penulis':<25} | {'Judul':<60} | {'Pembimbing I':<25} | {'Pembimbing II':<25}\")\n",
    "    print(\"=\" * 150)\n",
    "\n",
    "    for prodi in prodi_data:\n",
    "        print(f\"\\nScraping data for program: {prodi['name']}\")\n",
    "        print(\"-\" * 150)\n",
    "        \n",
    "        scraped_count = 0\n",
    "        page = 1\n",
    "        \n",
    "        while scraped_count < MAX_RECORDS_PER_PRODI:\n",
    "            url = f\"{prodi['url']}/{page}\"\n",
    "            \n",
    "            try:\n",
    "                r = requests.get(url)\n",
    "                r.raise_for_status()\n",
    "                soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "                jurnals = soup.select('li[data-cat=\"#luxury\"]')\n",
    "                \n",
    "                if not jurnals:\n",
    "                    print(f\"No more journals found on page {page}. Stopping for this program.\")\n",
    "                    break\n",
    "                \n",
    "                for jurnal in jurnals:\n",
    "                    if scraped_count >= MAX_RECORDS_PER_PRODI:\n",
    "                        break\n",
    "                        \n",
    "                    jurnal_url = jurnal.select_one('a.gray.button')['href']\n",
    "                    \n",
    "                    try:\n",
    "                        response = requests.get(jurnal_url)\n",
    "                        response.raise_for_status()\n",
    "                        soup1 = BeautifulSoup(response.content, \"html.parser\")\n",
    "                        isi = soup1.select_one('div#content_journal')\n",
    "                        \n",
    "                        if isi:\n",
    "                            judul = get_text_or_na(isi, ['a.title', 'b.title', 'h2.title'])\n",
    "                            penulis = get_data_from_span(isi, \"Penulis\")\n",
    "                            pembimbing_pertama = get_data_from_span(isi, \"Dosen Pembimbing I\")\n",
    "                            pembimbing_kedua = get_data_from_span(isi, \"Dosen Pembimbing II\")\n",
    "                            abstrak_indonesia = get_abstract_robust(isi, [\"Abstraksi\", \"Abstrak\"])\n",
    "                            abstrak_inggris = get_abstract_robust(isi, [\"Abstraction\", \"Abstract\", \"ABSTRACT\"])\n",
    "\n",
    "                            all_scraped_data[\"penulis\"].append(penulis)\n",
    "                            all_scraped_data[\"judul\"].append(judul)\n",
    "                            all_scraped_data[\"pembimbing_pertama\"].append(pembimbing_pertama)\n",
    "                            all_scraped_data[\"pembimbing_kedua\"].append(pembimbing_kedua)\n",
    "                            all_scraped_data[\"abstrak_indonesia\"].append(abstrak_indonesia)\n",
    "                            all_scraped_data[\"abstrak_inggris\"].append(abstrak_inggris)\n",
    "                            all_scraped_data[\"prodi\"].append(prodi['name'])\n",
    "                            \n",
    "                            total_data_count += 1\n",
    "                            scraped_count += 1\n",
    "                            \n",
    "                            # Print data to console in a formatted table row\n",
    "                            print(f\"{total_data_count:<4} | {prodi['name'][:20]:<20} | {penulis[:25]:<25} | {judul[:60]:<60} | {pembimbing_pertama[:25]:<25} | {pembimbing_kedua[:25]:<25}\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"ERROR: An error occurred while processing URL: {jurnal_url} - {e}\", file=sys.stderr)\n",
    "                \n",
    "                time.sleep(1) # Added delay to avoid overloading the server\n",
    "                page += 1\n",
    "                \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error fetching URL {url}: {e}\", file=sys.stderr)\n",
    "                break\n",
    "                \n",
    "    df = pd.DataFrame(all_scraped_data)\n",
    "    df.to_csv(\"pta_limited_data.csv\", index=False)\n",
    "    print(\"\\n---\")\n",
    "    print(f\"Scraping finished. Total data scraped: {total_data_count}\")\n",
    "    print(\"Data saved to pta_limited_data.csv\")\n",
    "    print(\"---\")\n",
    "    return df\n",
    "\n",
    "# Run the full scraping process\n",
    "scrape_pta_limited()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
